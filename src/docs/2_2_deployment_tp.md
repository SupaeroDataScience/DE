# Deploy your ML model into production

## Objectifs

L'objectif du TP est de convertir [ce notebook](https://colab.research.google.com/drive/1YnJVW-IbMkUhl7s5nJ7BsT5tsTTvMmUB?usp=sharing) en deux services containeris√©s : Un back-end qui est un serveur qui re√ßoit des images et sort des pr√©dictions, ainsi qu'un front-end qui vous permet d'envoyer des images au mod√®le et d'afficher les pr√©dictions sur lesdites images,

Afin de gagner du temps, les dockerfiles ont d√©j√† √©t√© construits et sont pr√™ts √† √™tre test√©s et d√©ploy√©s. Si vous souhaitez rentrer dans les d√©tails et √©crire vous-m√™me le code, vous pouvez consulter la version longue de ce TP (qui n'est pas √† jour). 

Nous allons donc voir :
- La cr√©ation d'un docker "backend" qui contient le mod√®le derri√®re une "API"
- L'interaction avec ce docker
- La cr√©ation d'un docker "frontend" qui contient une IHM permettant d'interagir plus facilement avec le backend
- docker-compose pour lancer des applications multi-container
- Le d√©ploiement du backend sur GCP
- Le test final

Nous nous pla√ßons dans un contexte "microservices" o√π le front-end et le backend sont 2 containers diff√©rents. Il aurait √©t√© possible de n'en faire qu'un qui contient les deux (un "monolithe"). Une architecture microservices peut avoir certains avantages (modularit√©, maintenance) mais est plus complexe √† mettre en oeuvre.

## 1 - Mise en place du projet Google Cloud Platform

Maintenant que vous avez vos cr√©dits, suivez les instructions du [1er TP Google Cloud Platform](https://supaerodatascience.github.io/DE/1_2_gcp_handson.html#1a-create-your-gcp-account) pour cr√©er votre propre projet GCP 

## 2 - D√©marrage du Code Space

D√©marrez un github codespace depuis le repository [https://github.com/fchouteau/isae-cloud-computing-codespace](https://github.com/fchouteau/isae-cloud-computing-codespace)

Il est n√©c√©ssaire d'utiliser un codespace √† partir de ce repository car il contient tout ce dont vous avez besoin pour ce TP.

![codespace](slides/static/img/codespacefchouteau.png)

Normalement, une fois le codespace lanc√©, vous devriez obtenir une interface vscode avec deux dossiers dont un nomm√© `tp-deployment`. Rendez-vous dans ce dossier,

Il y a plusieurs ressources : le `frontend` qui contient de quoi construire l'IHM, le `backend` qui contient de quoi construire le serveur, et des ressources de tests.

## 3 - Construction et tests du backend

Le `README.md` du dossier `backend` contient des d√©tails concernant la construction du serveur et de son API (qui √©tait auparavant laiss√© en exercice). Nous utilisons [FastAPI](https://fastapi.tiangolo.com/) qui un framework de construction d'applications Web.

Le code principal se trouve dans `app.py`. On d√©clare des "routes" (des m√©thodes d'interactions avec le serveur) puis on leur assigne des fonctions.

Par exemple, vous pouvez regarder la route `predict` qui est associ√©e √† la fonction du m√™me nom.

```python
@app.post(
    "/predict",
    description="Send a base64 encoded image + the model name, get detections",
    response_description="Detections + Processing time",
    response_model=Result,
)
```

Cette fonction effectue l'inf√©rence sur l'image qui est donn√©e via la requ√™te REST vers la route /predict.

Afin de mieux illustrer les possibilit√©s d'int√©raction avec ce serveur, nous allons le lancer localement, en utilisant l'image docker d√©j√† construite (Remarque: vous pouvez reproduire le docker en lan√ßant `docker build -f Dockerfile -t eu.gcr.io/third-ridge-138414/yolo-v5:1.2`)

Lancez la commande suivante `docker run --rm -p 8000:8000 eu.gcr.io/third-ridge-138414/yolo-v5:1.2`

Cela lance un container depuis l'image docker du backend en exposant le port 8000.

Connectez-vous au port 8000 du codespace. Vous devriez avoir une page vierge qui contient `"YOLO-V5 WebApp created with FastAPI"`

Nous allons maintenant regarder la documentation de l'application. Celle-ci est automatiquement g√©n√©r√©e √† partir du code de `app.py` et est disponible sur la route `/docs` 

Connectez-vous donc √† la route `/docs` en rajoutant ce terme √† l'URL du codespace. 

![fastapidoc](slides/static/img/apidoc.png)

Cette page web d√©crit les diff√©rentes routes accessibles et leurs m√©thodes d'int√©raction, ainsi que les formats d'entr√©e et de sortie. C'est la documentation de l'API et lorsque vous interagissez avec le serveur, c'est la seule chose dont vous avez besoin.

Nous allons maintenant interagir avec ce serveur.

Dans le dossier `backend` se trouve un fichier python `test_webapp.py`. Il va automatiquement envoyer les bonnes requ√™tes au serveur. Executez-le (`python test_webapp.py`), vous devriez voir s'afficher des tests correspondants au code, ainsi que les pr√©dictions des chats sur l'image `cats.png` 

Laissez le terminal avec le container d√©marr√© pour l'instant,

## 4 - Construction et tests du frontend

Comme vous aurez pu le constater, ce n'est pas tr√®s intuitif d'interagir avec le backend via des scripts, on aimerait pouvoir visualiser plus facilement les pr√©dictions, faire des seuils sur la confiance des objets, etc...

Pour cela nous allons cr√©er une application `streamlit` (remarque: pour une introduction √† streamlit rendez-vous dans la [section 6 du BE](https://supaerodatascience.github.io/DE/1_4_be.html#6-lets-discover-streamlit))

Dans votre codespace, d√©marrez un nouveau terminal puis allez dans le dossier `frontend`. L√† encore, le fichier `app.py` contient le code de l'applicaiton streamlit. Celle-ci va r√©cup√©rer une image que vous allez uploader (image de votre choix) puis l'envoyer au serveur dont vous sp√©cifiez l'IP dans la case en haut √† gauche.

Nous allons lancer cette application,

`docker run --rm -p 8501:8501 --network="host" eu.gcr.io/third-ridge-138414/yolo-v5-streamlit:1.5`

Rendez-vous sur le port 8501 de votre github codespace, 

![streamlit](slides/static/img/companion.png)

La premi√®re √©tape est de renseigner l'adresse (URL) du backend. Pour tester que vous arrivez bien √† joindre le serveur, cliquez sur le bouton "IS ALIVE". Ce bouton (voir code dans `app.py`) envoie une requ√™te √† la route /health pour v√©rifier que le serveur est vivant.

Par d√©faut, l'URL du serveur est `http://localhost:8000` ce qui semble correct car nous avons ouvert un docker sur le port 8000.

Vous pouvez maintenant tester le serveur, et s'il marche, uploader une image de votre choix avec le bouton upload puis lancer une pr√©diction. Cela va uploader l'image dans le frontend, puis envoyer une requ√™te POST √† `http://url-du-serveur/predict` puis r√©cup√©rer les r√©sultats (le `json`) et l'interpr√©ter correctement.

Vous noterez que nous avons d√©marr√© le frontend avec l'argument ` --network="host"`. Cela permet au container d'avoir acc√®s au `localhost` (d'√™tre sur le m√™me r√©seau que l'h√¥te). Sans cet argument, les containers sont sur des r√©seaux s√©par√©s et ne se voient pas.

Vous pouvez maintenant stopper les deux containers (backend et frontend)

## 5 - docker-compose

Pour simplifier cette √©tape de d√©ploiement multi-containers qui peut √™tre fastidieuse (imaginez une application √† 4, 5 containers !), une solution nomm√©e `docker-compose` existe. Voir une [introduction √† docker-compose](https://blog.stephane-robert.info/docs/conteneurs/orchestrateurs/docker-compose/)

Cette solution permet de lancer une s√©rie de containers en les assignant √† un m√™me r√©seau, de fa√ßon d√©clarative, c'est √† dire que l'on renseigne dans un fichier de configuration la mise en place des containers.

Notre `docker-compose.yml` se trouve dans le dossier `tp-deployment`

```yaml
version: '3'
services:
  yolo:
    image: "eu.gcr.io/third-ridge-138414/yolo-v5:1.2"
    ports:
      - "8000:8000"
    hostname: yolo
  streamlit:
    image: "eu.gcr.io/third-ridge-138414/yolo-v5-streamlit:1.5"
    ports:
      - "8501:8501"
    hostname: streamlit
```

Ce fichier de configuration indique qu'au lancement le frontend et le backend vont se lancer simultan√©ment, exposer leurs ports respectifs, et pouvoir communiquer entre eux via leurs "hostnames".

Nous allons lancer notre application par ce bias en lan√ßant la commande `docker-compose up`

Voir doc docker-compose : [https://docs.docker.com/compose/reference/](https://docs.docker.com/compose/reference/)

Cela va directement d√©marrer nos deux services, que vous pouvez retrouver sur les ports 8000 (backend) et 8501 (frontend)

Comme pr√©c√©demment, vous pouvez vous connecter au frontend sur le port 8501 du codespace pour interagir directement avec le backend. La petite nuance est que ce backend est disponible sur `http://yolo:8000` plut√¥t que `http://localhost:8000` car le `docker-compose` a nomm√© les containers avec un hostname correspondant √† celui sp√©cifi√© (et les a mis en r√©seau)

Une fois que vous avez interagi avec votre d√©ploiement, nous allons maintenant d√©ployer le backend sur un serveur sur google cloud.

## 6 - Deploiement du backend sur une VM Google Compute Engine

Nous allons maintenant d√©marrer une instance de VM Google Compute Engine et directement y d√©ployer un container. Vous avez d√©j√† vu cette m√©thode dans la [section streamlit du BE](https://supaerodatascience.github.io/DE/1_4_be.html#64-deployment-in-a-vm)

N'oubliez pas de connecter votre github codespace √† votre projet gcp en utilisant `gcloud init`

R√©cup√©rez votre project_id gcp :  `PROJECT_ID=$(gcloud config get-value project 2> /dev/null)``

Puis nous allons cr√©er directement une VM en y d√©ployant un container. Notez que l'on utilise cette fois un OS d√©di√© √† l'h√©bergement de containers (pas pr√©vu pour s'y connecter en ssh) plut√¥t qu'ubuntu comme pr√©c√©demment. 

```bash
gcloud compute instances create-with-container fch-yolo-backend \
    --project=${PROJECT_ID} \
    --zone=europe-west1-b \
    --machine-type=n1-standard-2 \
    --image=projects/cos-cloud/global/images/cos-stable-109-17800-66-27 \
    --boot-disk-size=20GB \
    --boot-disk-type=pd-standard \
    --container-image=eu.gcr.io/third-ridge-138414/yolo-v5:1.2 \
    --container-restart-policy=always
```

Note : Si vous utilisez votre propre projet GCP, vous devez ouvrir le port 8000 √† internet public pour pouvoir y acc√©der. Utilisez cette commande : 

```bash
gcloud compute --project=${PROJECT_ID} firewall-rules create open-8000 --direction=INGRESS --priority=1000 --network=default --action=ALLOW --rules=tcp:8000 --source-ranges=0.0.0.0/0 
```

## 7 - Tests

Nous allons maintenant tester que notre backend est bien d√©ploy√©. Il faut pour cela relancer le front-end et changer l'IP pour l'IP de la machine virtuelle pr√©c√©demment lanc√©e

- relancez le docker du frontend `docker run --rm -p 8501:8501 eu.gcr.io/third-ridge-138414/yolo-v5-streamlit:1.5`
- connectez vous au port 8501 du github codespace, comme pr√©c√©demment, et modifiez l'IP du backend pour qu'il corresponde √† celle du serveur distant (toujours sur le port 8000)
- si vous envoyez une requ√™te, elle est maintenant transmise au backend !

## 8. Yay !

!!! success
    üçæ *Et voil√†, vous avez d√©ploy√© votre premier mod√®le sur le cloud*

N'oubliez pas de supprimer votre VM GCP une fois le travail termin√©
